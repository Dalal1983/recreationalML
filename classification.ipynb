{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from tensorflow.contrib.layers import fully_connected, convolution2d, flatten, batch_norm, max_pool2d, dropout\n",
    "from tensorflow.contrib.layers import l2_regularizer, l1_regularizer\n",
    "from tensorflow.python.ops.nn import relu, softmax\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "\n",
    "from batcher import Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(t, n_classes):\n",
    "    out = np.zeros((t.shape[0], n_classes))\n",
    "    for row, col in enumerate(t):\n",
    "        out[row, col] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batcher = Batcher('text', rep='textdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples, labels = batcher.get_batch(58,10)\n",
    "examples = (1+examples)/2\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, im in enumerate(examples):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(im)\n",
    "    plt.title(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_batch(sess, batch):\n",
    "    x_batch, y_batch = batch\n",
    "    fetches = [train_step]\n",
    "    feed = {x_pl: x_batch, y_pl: onehot(y_batch, n_classes), is_training: True}\n",
    "    sess.run(fetches, feed)\n",
    "    \n",
    "    \n",
    "def eval_batch(sess, batch):\n",
    "    x_batch, y_batch = batch\n",
    "    fetches = [cross_entropy, accuracy]\n",
    "    feed = {x_pl: x_batch, y_pl: onehot(y_batch, n_classes), is_training: False}\n",
    "    batch_loss, batch_acc = sess.run(fetches, feed)\n",
    "    \n",
    "    return batch_loss, batch_acc\n",
    "\n",
    "def predict_batch(sess, batch):\n",
    "    x_batch, y_batch = batch\n",
    "    fetches = [y]\n",
    "    feed = {x_pl: x_batch, is_training: False}\n",
    "    res = sess.run(fetches, feed)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(sess, batcher, n_samples_train=15000, eval_train=True, track_valid = True, n_samples_valid=5000, \\\n",
    "        n_epochs=10, batch_size=100, early_stopping=True):\n",
    "    \"\"\"Fits the model to the training data.\n",
    "    If track_valid=True, the model will be evaluated on the validation data too\"\"\"\n",
    "    \n",
    "    n_batches_train = n_samples_train // batch_size\n",
    "    \n",
    "    if eval_train:\n",
    "        train_acc, train_loss = [], []\n",
    "        \n",
    "    if track_valid:\n",
    "        valid_acc, valid_loss = [], []\n",
    "        n_batches_valid = n_samples_valid // batch_size\n",
    "        \n",
    "    if early_stopping:\n",
    "        patience = 3\n",
    "        cnt = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        batcher.reset_iterator()\n",
    "        \n",
    "        print('Epoch', epoch+1)\n",
    "        print('Training:', end=\" \")\n",
    "        \n",
    "        for i in range(n_batches_train):\n",
    "            batch = batcher.next_batch(batch_size)\n",
    "            fit_batch(sess, batch)\n",
    "            if (i+1)%10==0:\n",
    "                print(i+1, end=\" \")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        if eval_train:\n",
    "            batcher.reset_iterator()\n",
    "            cur_loss = 0\n",
    "            cur_acc = 0\n",
    "            print('Evaluating model on training set...', end=' ')\n",
    "            for i in range(n_batches_train):\n",
    "                batch = batcher.next_batch(batch_size)\n",
    "                batch_loss, batch_acc = eval_batch(sess, batch)\n",
    "                cur_loss += batch_loss\n",
    "                cur_acc += batch_acc\n",
    "                if (i+1)%10==0:\n",
    "                    print(i+1, end=\" \")\n",
    "\n",
    "            train_loss.append(cur_loss/n_batches_train)\n",
    "            train_acc.append(cur_acc/n_batches_train)\n",
    "        \n",
    "        if track_valid:\n",
    "            print()\n",
    "            cur_loss = 0\n",
    "            cur_acc = 0\n",
    "            print('Evaluating model on validation set...', end=' ')\n",
    "            for i in range(n_batches_valid):\n",
    "                batch = batcher.next_batch(batch_size)\n",
    "                batch_loss, batch_acc = eval_batch(sess, batch)\n",
    "                cur_loss += batch_loss\n",
    "                cur_acc += batch_acc\n",
    "                if (i+1)%10==0:\n",
    "                    print(i+1, end=\" \")\n",
    "                    \n",
    "            if early_stopping and len(valid_loss) > 1 and valid_loss[-1] > valid_loss[-2]:\n",
    "                cnt += 1\n",
    "                    \n",
    "            print()\n",
    "\n",
    "            valid_loss.append(cur_loss/n_batches_valid)\n",
    "            valid_acc.append(cur_acc/n_batches_valid)\n",
    "        \n",
    "        if eval_train:\n",
    "            print('train loss =', train_loss[-1], 'train acc =', train_acc[-1])\n",
    "        if track_valid:\n",
    "            print('valid loss =', valid_loss[-1], 'valid acc =', valid_acc[-1])\n",
    "            \n",
    "        if track_valid and early_stopping and cnt == patience:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "    \n",
    "    return train_loss, train_acc, valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train_valid(train_values, valid_values):\n",
    "    xaxis = np.arange(len(train_values))\n",
    "    plt.plot(xaxis, train_values, c='b', label='Training')\n",
    "    plt.plot(xaxis, valid_values, c='r', label='Validation')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "def plot_loss_acc(res):\n",
    "    train_loss, train_acc, valid_loss, valid_acc = res\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plot_train_valid(train_loss, valid_loss)\n",
    "    plt.title('loss')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plot_train_valid(train_acc, valid_acc)\n",
    "    plt.title('accuracy')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(sess, path):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, path)\n",
    "    \n",
    "def restore(sess, path, filename):\n",
    "    saver = tf.train.import_meta_graph(path+filename)\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resmodule(input_tensor, n_filters, reg_const=0.1):\n",
    "    \n",
    "    conv1 = convolution2d(input_tensor, n_filters, kernel_size=[3,3], activation_fn=relu, \\\n",
    "                          weights_regularizer=l2_regularizer(reg_const), \\\n",
    "                          normalizer_fn=None, padding='SAME')\n",
    "    conv2 = convolution2d(conv1, n_filters, kernel_size=[3,3], activation_fn=None, \\\n",
    "                          weights_regularizer=l2_regularizer(reg_const),\\\n",
    "                          normalizer_fn=None, padding='SAME')\n",
    "    \n",
    "    return relu(input_tensor+conv2)\n",
    "\n",
    "def transition_resmodule(input_tensor, n_filters_in, n_filters_out, reg_const=0.1):\n",
    "    \"\"\"The original ResNet paper considers both zero-padding and projection shortcuts when the dimension increases.\n",
    "    We do only zero-padding, as the performance is said to be almost the same with lower complexity.\"\"\"\n",
    "    \n",
    "    conv1 = convolution2d(input_tensor, n_filters_out, kernel_size=[3,3], stride = 2, activation_fn=relu, \\\n",
    "                          weights_regularizer=l2_regularizer(reg_const), \\\n",
    "                          normalizer_fn=None, padding='SAME')\n",
    "    conv2 = convolution2d(conv1, n_filters_out, kernel_size=[3,3], activation_fn=None, \\\n",
    "                          weights_regularizer=l2_regularizer(reg_const), \\\n",
    "                          normalizer_fn=None, padding='SAME')\n",
    "    \n",
    "    # since we change the spatial dimension, we must take the input with stride 2 (original paper too)\n",
    "    strided = input_tensor[:,::2,::2,:]\n",
    "    \n",
    "    n_zeros = n_filters_out - n_filters_in\n",
    "    paddings = [[0,0], [0,0], [0,0], [0, n_zeros]]\n",
    "    padded = tf.pad(strided, paddings, \"CONSTANT\")  \n",
    "    \n",
    "    return relu(padded + conv2)\n",
    "\n",
    "\n",
    "def module(input_tensor, n_filters, n_layers=2, kernel=[3,3], stride=1, reg_const=0.1):\n",
    "    \n",
    "    conv = convolution2d(input_tensor, n_filters, kernel_size=kernel, stride=stride, activation_fn=relu, \\\n",
    "                         weights_regularizer=l2_regularizer(reg_const), padding='SAME')\n",
    "    \n",
    "    for i in range(n_layers-1):\n",
    "        conv = convolution2d(conv, n_filters, kernel_size=kernel, stride=stride, activation_fn=relu, \\\n",
    "                             weights_regularizer=l2_regularizer(reg_const), padding='SAME')\n",
    "\n",
    "    pool = max_pool2d(conv, kernel_size=[2,2])\n",
    "    \n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h, w, d = 128, 128, 3\n",
    "n_classes = 2\n",
    "kernel = [3,3]\n",
    "stride = [1,1]\n",
    "reg = 1.0\n",
    "\n",
    "reset_default_graph()\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, h, w, d])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "\"\"\"\n",
    "mod1 = module(x_pl, 32, n_layers=3, kernel=kernel, stride=stride, reg_const=reg)\n",
    "mod2 = module(mod1, 64, n_layers=3, kernel=kernel, stride=stride, reg_const=reg)\n",
    "mod3 = module(mod2, 128, n_layers=2, kernel=kernel, stride=stride, reg_const=reg)\n",
    "\n",
    "l_flatten = flatten(mod3)\n",
    "l_dropout = dropout(l_flatten, keep_prob=0.5, is_training=is_training)\n",
    "\n",
    "l1 = fully_connected(l_dropout, 256, activation_fn=relu, weights_regularizer=l2_regularizer(reg))\n",
    "l1_dropout = dropout(l1, keep_prob=0.5, is_training=is_training)\n",
    "\n",
    "y = fully_connected(l1_dropout, n_classes, activation_fn=softmax)\n",
    "\"\"\"\n",
    "\n",
    "conv1 = convolution2d(x_pl, 32, kernel_size=[5,5], stride=2, activation_fn=relu, \\\n",
    "                         weights_regularizer=l2_regularizer(reg), padding='SAME')\n",
    "pool1 = max_pool2d(conv1, kernel_size=[2,2])\n",
    "\n",
    "mod = resmodule(pool1, 32, reg)\n",
    "mod = resmodule(mod, 32, reg)\n",
    "\n",
    "mod = transition_resmodule(mod, 32, 64, reg)\n",
    "mod = resmodule(mod, 64, reg)\n",
    "\n",
    "mod = transition_resmodule(mod, 64, 128, reg)\n",
    "\n",
    "pool2 = max_pool2d(mod, kernel_size=[2,2])\n",
    "\n",
    "y = fully_connected(flatten(pool2), n_classes, activation_fn=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pl = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8))\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "loss = cross_entropy\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_pl, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = fit(sess, batcher, n_epochs=10, n_samples_train=8000, n_samples_valid=2000, early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(sess, 'xsave/3mod_20ep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs, true_labels = batcher.next_batch(48)\n",
    "preds = predict_batch(sess, (imgs, true_labels))\n",
    "imgs = (1+imgs)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,40))\n",
    "\n",
    "for i,pred in enumerate(preds):\n",
    "    plt.subplot(12,4,i+1)\n",
    "    plt.imshow(imgs[i])\n",
    "    s = 'Vrai : %d, Probabilit√© X: %.02f' % (true_labels[i], pred[1])\n",
    "    plt.title(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
